for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
datasim <- data.frame(df[,i])
g <- ggplot(datasim, aes(x = df[,i]), binwidth = 2) +
geom_histogram(aes(y = ..density..), fill = 'red', alpha = 0.5) +
geom_density(colour = 'blue') + xlab(expression(bold('Dados'))) +
ylab(expression(bold('Densidade')))
print(g)
}
}
# Coeficiente de Assimetria (Skew)
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
ca <- skewness(df[,i])
print(ca)
}
}
# Coeficiente de Curtose
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
ck <- kurtosis(df[,i])
print(ck)
}
}
par(mfrow=c(1,2))
for(i in var.fct[-1]){
CrossTable(df$class,
df[,i],
prop.t = T,
chisq = T,
digits = 2,
dnn = c("class", i))
}
# Diagramas de Dispersão - Matriz de Correlação
plot(df[,c(var.num, var.num_con)])
# Coeficiente de Correlação - feature numérico x target categórico
cor(df$Age,
df[target_names] %>% unlist() %>% as.numeric())
# var, cov e cor calculam a variância de x e a covariância ou correlação de x e y se esses forem vetores.
# Se x e y são matrizes, então as covariâncias (ou correlações) entre as colunas de x e as colunas de y são calculadas.
# Gráfico dos Coeficientes de Correlação
# df[target_names] = df[target_names] %>% unlist() %>% as.numeric()
# cor.plot(df[,c(var.num, target_names)])
df[target_names] = df[target_names] %>% unlist() %>% as.numeric()
df[feature_names] = df[feature_names] %>% unlist() %>% as.numeric()
M = cor(df[,c(feature_names, target_names)])
corrplot(M, method = 'color')
cov(df[,c(var.num, target_names)])
# Diagramas de Dispersão + Coeficientes de Correlação
pairs.panels(df[,c(var.num, target_names)])
# Boxplots valor conforme as Categóricas
par(mfrow=c(1,3), cex = 0.65)
for(i in var.fct){
boxplot(df[,var.num] ~ df[,i],
beside = TRUE,
xlab = names(df)[grep(i, names(df))],
ylab = names(df)[grep(var.num, names(df))])
}
# Boxplots Numéricas conforme as Survived
par(mfrow=c(1,1))
for(i in 0:length(df)){
if(is.numeric(df[,i])){
boxplot(df[,i] ~ class, ylab = names(df)[i], data = df)
}
}
Z_df <- dget(file = "data/df.R")
# ------------------------------------------------------------------------------
# Padroniza
Z_df[c(var.num, var.num_con)] <- sapply(Z_df[c(var.num, var.num_con)], scale)
# Exporta Dados Padronizados
dput(Z_df, file = "data/Z_df.R")
print('Original:')
stargazer(df, type = "text")
print('Padronizado:')
stargazer(Z_df, type = "text")
# Packages
# ==============================================================================
## install.packages("caret")
#library(caret)
## install.packages("kernlab")
#library(kernlab)
# ==============================================================================
# Carrega conjuntos de dados especificados
# ou lista os conjuntos de dados disponíveis.
#data(df)
#df = Z_df
# Cria uma série de partições de teste / treinamento
inTrain <- createDataPartition(y = df$class, # Um vetor de resultados.
p = 0.75,     # Percentual para treino.
list = FALSE)
# Coloca cada partição em um dataframe diferente
training <- df[inTrain,]
testing <- df[-inTrain,]
dim(training)
# Exporta os dados
dput(training, file = "data/training.R")
dput(testing,  file = "data/testing.R")
massa <- training
mdl.tst <- testing
# Configurando uma semente para que o Gerador Aleatório de Números seja reproduzível.
set.seed(1618)
# Criando uma coluna com índices randômicos.
massa[ ,'index'] <- ifelse(runif(nrow(massa)) < 0.8, 1, 0)
# Criando os conjuntos de treino e de validação.
mdl.trn <- massa[massa$index == 1, ]
mdl.vld <- massa[massa$index == 0, ]
# Obtem o índice (posição), no vetor de nomes, onde corresponde ao valor 'index'.
col_idx <- grep('index', names(mdl.trn))
# Remove a coluna 'index' dos datasets, utilizando a posição obtida.
mdl.trn <- mdl.trn[ , -col_idx]
mdl.vld <- mdl.vld[ , -col_idx]
# Gerar Modelos de Classificação
ajt.trn <- glm(formula = class ~ .,
family = gaussian,
data = mdl.trn)
summary(ajt.trn)
pred <- predict(
ajt.trn,
newdata = mdl.vld,
type = "response")
# Criando um dataframe com os dados observados e os preditos.
previsoes <- data.frame(
observado = mdl.vld[,target_names] %>% factor(labels = c("Negative", "Positive")),
previsto = pred
%>%
round() %>%
factor(labels = c("Negative", "Positive")))
CrossTable(previsoes$observado,
previsoes$previsto)
chisq.test(previsoes$observado, previsoes$previsto)
hist(pred, xlab = "Predições", main = "Histograma de Predições")
cm <- confusionMatrix(previsoes$observado, previsoes$previsto, positive = 'Positive')
print(cm)
fourfoldplot(cm$table)
mosaicplot(cm$table, color = TRUE, shade = TRUE, main = "Mosaico para Confusion Matrix")
acuracia <- (cm$table[1,1] + cm$table[2,2])/(cm$table[1,1] + cm$table[1,2] + cm$table[2,1] + cm$table[2,2])
# Precision
precisao <- cm$table[1,1] / (cm$table[1,1] + cm$table[1,2])
sensibilidade <- cm$table[1,1] / (cm$table[1,1] + cm$table[2,1])
f1 <- (2 * sensibilidade * precisao) / (sensibilidade + precisao)
metricas <- data.frame(
"Acuracia"      = acuracia,
"Precisao"      = precisao,
"Sensibilidade" = sensibilidade,
"F1-Score"      = f1)
metricas
class1 <- predict(ajt.trn, newdata = mdl.vld, type = "response")
class2 <- mdl.vld[target_names]
pred <- prediction(class1, class2)
perf <- performance(pred, "tpr", "fpr")
# Gerando uma curva ROC em R
plot(perf, col = rainbow(10, alpha = NULL))
chisq.test(previsoes$observado, previsoes$previsto)
predict(ajt.trn,
newdata = mdl.tst,
type = "response") %>%
round() %>%
factor(labels = c("Negative", "Positive")) -> predicao
CrossTable(predicao, prop.t = T, digits = 2)
require(moments) # Coeficiente de Assimetria
#install.packages("rvest")
require(rvest) # %>% - Concatenação no uso de funções
# install.packages("fdth")
require(fdth) # Execute tabelas de distribuição de frequência, histogramas e polígonos associados de objetos vetoriais, data.frame e matriz para variáveis numéricas e categóricas.
# install.packages("tidyverse")
require(tidyverse) # Para função tibble()
# install.packages("gmodels")
require(gmodels)
# install.packages("mice")
require(mice)
# Scatterplot Matrix
# install.packages("psych")
require(psych)
# install.packages('stargazer')
require(stargazer)
# Gerando uma curva ROC em R
# install.packages("ROCR")
require(ROCR)
# install.packages("e1071")
require(e1071)
# Gerando Confusion Matrix com o Caret
# install.packages("caret")
require(caret)
# install.packages("Amelia")
# require(Amelia) # missmap - Mapa de valores missing
require(xtable)
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")
#install.packages("DT")
require(DT)
require(knitr)
# require(lemon)
# knit_print.data.frame <- lemon_print
#install.packages("ggplot2")
require(ggplot2)
#install.packages("dplyr")
require(dplyr)
#install.packages("hrbrthemes")
require(hrbrthemes)
# install.packages("gridExtra")
require(gridExtra)
# install.packages('corrplot')
library(corrplot)
#install.packages("skimr")
library(skimr)
DATADIC = 'data/dictionary.txt'
df <- read.csv(
file = 'data/diabetes.csv',
stringsAsFactors = TRUE)
df %>% head(1) %>% kable()
target_names <- c('class')
feature_names = names(df[!names(df) %in% target_names])
# Read a txt file
read.delim(DATADIC, sep='|')
skim(df)
# Exporta os dados
dput(df, file = "data/df.R")
# Qualitativas Nominais
var.fct <- c()
for(i in 1:ncol(df)){
if(is.factor(df[,i]) && !is.ordered(df[,i])){
var.fct = c(var.fct, names(df)[i])}}
# Qualitativas Ordinais
var.fct_ord <- c()
for(i in 1:ncol(df)){
if(is.factor(df[,i]) && is.ordered(df[,i])){
var.fct_ord = c(var.fct_ord, names(df)[i])}}
# Quantitativas Discretas
var.num <- c()
for(i in 1:ncol(df)){
if(is.integer(df[,i])){
var.num <- c(var.num, names(df)[i])}}
# Quantitativas Contínuas
var.num_con <- c()
for(i in 1:ncol(df)){
if(typeof(df[,i]) == "double"){
var.num_con <- c(var.num_con, names(df)[i])}}
d1 = data.frame("Qualitativas_Nominais - " = var.fct)
d2 = data.frame("Qualitativas_Ordinais - " = var.fct_ord)
d3 = data.frame("Quantitativas_Discretas - " = var.num)
d4 = data.frame("Quantitativas_Contínuas - " = var.num_con)
var_type_list = list(d1, d2, d3, d4)
for(i in var_type_list){
if(dim(i)[1] != 0){
print(i)}}
describe(df) %>% kable()
# Distribuição de Frequências para as Variáveis Qualitativas Nominais
for(i in var.fct){
fdt_cat(df[,i]) %>%
tibble() -> df_var
names(df_var)[1] = c(colnames(df[i]))
print(kable(df_var[order(df_var[2], decreasing = TRUE),]))
}
# Gráficos de barras para variáveis categóricas
par(mfrow=c(2,2), cex = 0.55)
for(i in c(var.fct, var.fct_ord)){
bp <- barplot(table(df[i]),
main = names(df[i]),
ylim = c(0, max(table(df[i]))*1.4),
col = "green")
text(x = as.vector(bp),
y = table(df[,i]) + 2,
label =  round(table(df[i]), 1),
pos = 3,
col = "black")}
par(mfrow=c(2,1))
# Distribuição de Frequências: Variáveis Quantitativas
for(i in var.num_con){
df_n <- fdt(df[,i])
#names(df)[[1]] = c(colnames(aed.trn[i]))
print(kable(df_n, caption = "Title of the table"))
}
# Build dataset with different distributions
# Represent it
df %>%
ggplot(aes(x = Age, fill=Gender)) +
geom_histogram(
color="#e9ecef",
alpha=0.6,
position = 'identity',
binwidth = 5)
df %>%
ggplot( aes(x=Age, fill=Gender) ) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual( values=c("#69b3a2", "#404080") ) +
labs(fill="Sexo")
stargazer(df, median = T, mean.sd = T, iqr = T, type = "text", title = "Sumário Estatístico")
n = c()
m = c()
# Moda
for(i in 1:ncol(df)){
if(is.factor(df[,i])){
n = c(n, names(df)[i])
m = c(m, moda(df[,i]))
}
}
kable(data.frame("Variável" = n, "Moda" = m), align = "l")
# Quintis
par(mfrow=c(2,2))
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
quintis = seq(.2, .8, .2)
q <- data.frame(quantile(df[,i], quintis))
names(q) <- names(df)[i]
print(q)
}
}
# libraries
#install.packages("gridExtra")
library(ggplot2)
library(gridExtra)
# Make 3 simple graphics:
g1 <- ggplot(df, aes(x=Age)) + geom_density(fill="slateblue")
g2 <- ggplot(df, aes(x=Age, y=class, color=class)) + geom_point(size=5) + theme(legend.position="none")
g3 <- ggplot(df, aes(x=factor(Gender), y=Age, fill=class)) + geom_boxplot() + theme(legend.position="none")
g4 <- ggplot(df , aes(x=factor(Gender), fill=factor(Gender))) +  geom_bar()
# Plots
grid.arrange(g2, arrangeGrob(g3, g4, ncol=2), nrow = 2)
grid.arrange(g1, g2, g3, nrow = 3)
grid.arrange(g2, arrangeGrob(g3, g4, ncol=2), nrow = 1)
grid.arrange(g2, arrangeGrob(g3, g4, nrow=2), nrow = 1)
# Amplitude Total
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
amp <- diff(range(df[,i]))
print(amp)
}
}
# Variância
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
print(
var(df[,i])
)
}
}
# Desvio Padrão
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
print(
sd(df[,i])
)
}
}
# Coeficiente de Variação
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
cv <- 100*sd(df[,i]/mean(df[,i]))
print(cv)
}
}
par(mfrow=c(2,2))
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
datasim <- data.frame(df[,i])
g <- ggplot(datasim, aes(x = df[,i]), binwidth = 2) +
geom_histogram(aes(y = ..density..), fill = 'red', alpha = 0.5) +
geom_density(colour = 'blue') + xlab(expression(bold('Dados'))) +
ylab(expression(bold('Densidade')))
print(g)
}
}
# Coeficiente de Assimetria (Skew)
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
ca <- skewness(df[,i])
print(ca)
}
}
# Coeficiente de Curtose
for(i in 1:ncol(df)){
if(is.numeric(df[,i])){
ck <- kurtosis(df[,i])
print(ck)
}
}
par(mfrow=c(1,2))
for(i in var.fct[-1]){
CrossTable(df$class,
df[,i],
prop.t = T,
chisq = T,
digits = 2,
dnn = c("class", i))
}
# Diagramas de Dispersão - Matriz de Correlação
plot(df[,c(var.num, var.num_con)])
# Coeficiente de Correlação - feature numérico x target categórico
cor(df$Age,
df[target_names] %>% unlist() %>% as.numeric())
# var, cov e cor calculam a variância de x e a covariância ou correlação de x e y se esses forem vetores.
# Se x e y são matrizes, então as covariâncias (ou correlações) entre as colunas de x e as colunas de y são calculadas.
# Gráfico dos Coeficientes de Correlação
# df[target_names] = df[target_names] %>% unlist() %>% as.numeric()
# cor.plot(df[,c(var.num, target_names)])
df[target_names] = df[target_names] %>% unlist() %>% as.numeric()
df[feature_names] = df[feature_names] %>% unlist() %>% as.numeric()
M = cor(df[,c(feature_names, target_names)])
corrplot(M, method = 'color')
cov(df[,c(var.num, target_names)])
# Diagramas de Dispersão + Coeficientes de Correlação
pairs.panels(df[,c(var.num, target_names)])
# Boxplots valor conforme as Categóricas
par(mfrow=c(1,3), cex = 0.65)
for(i in var.fct){
boxplot(df[,var.num] ~ df[,i],
beside = TRUE,
xlab = names(df)[grep(i, names(df))],
ylab = names(df)[grep(var.num, names(df))])
}
# Boxplots Numéricas conforme as Survived
par(mfrow=c(1,1))
for(i in 0:length(df)){
if(is.numeric(df[,i])){
boxplot(df[,i] ~ class, ylab = names(df)[i], data = df)
}
}
Z_df <- dget(file = "data/df.R")
# ------------------------------------------------------------------------------
# Padroniza
Z_df[c(var.num, var.num_con)] <- sapply(Z_df[c(var.num, var.num_con)], scale)
# Exporta Dados Padronizados
dput(Z_df, file = "data/Z_df.R")
print('Original:')
stargazer(df, type = "text")
print('Padronizado:')
stargazer(Z_df, type = "text")
# Packages
# ==============================================================================
## install.packages("caret")
#library(caret)
## install.packages("kernlab")
#library(kernlab)
# ==============================================================================
# Carrega conjuntos de dados especificados
# ou lista os conjuntos de dados disponíveis.
#data(df)
#df = Z_df
# Cria uma série de partições de teste / treinamento
inTrain <- createDataPartition(y = df$class, # Um vetor de resultados.
p = 0.75,     # Percentual para treino.
list = FALSE)
# Coloca cada partição em um dataframe diferente
training <- df[inTrain,]
testing <- df[-inTrain,]
dim(training)
# Exporta os dados
dput(training, file = "data/training.R")
dput(testing,  file = "data/testing.R")
massa <- training
mdl.tst <- testing
# Configurando uma semente para que o Gerador Aleatório de Números seja reproduzível.
set.seed(1618)
# Criando uma coluna com índices randômicos.
massa[ ,'index'] <- ifelse(runif(nrow(massa)) < 0.8, 1, 0)
# Criando os conjuntos de treino e de validação.
mdl.trn <- massa[massa$index == 1, ]
mdl.vld <- massa[massa$index == 0, ]
# Obtem o índice (posição), no vetor de nomes, onde corresponde ao valor 'index'.
col_idx <- grep('index', names(mdl.trn))
# Remove a coluna 'index' dos datasets, utilizando a posição obtida.
mdl.trn <- mdl.trn[ , -col_idx]
mdl.vld <- mdl.vld[ , -col_idx]
# Gerar Modelos de Classificação
ajt.trn <- glm(formula = class ~ .,
family = gaussian,
data = mdl.trn)
summary(ajt.trn)
pred <- predict(
ajt.trn,
newdata = mdl.vld,
type = "response")
# Criando um dataframe com os dados observados e os preditos.
previsoes <- data.frame(
observado = mdl.vld[,target_names] %>% factor(labels = c("Negative", "Positive")),
previsto = pred
%>%
round() %>%
factor(labels = c("Negative", "Positive")))
CrossTable(previsoes$observado,
previsoes$previsto)
chisq.test(previsoes$observado, previsoes$previsto)
hist(pred, xlab = "Predições", main = "Histograma de Predições")
cm <- confusionMatrix(previsoes$observado, previsoes$previsto, positive = 'Positive')
print(cm)
fourfoldplot(cm$table)
mosaicplot(cm$table, color = TRUE, shade = TRUE, main = "Mosaico para Confusion Matrix")
acuracia <- (cm$table[1,1] + cm$table[2,2])/(cm$table[1,1] + cm$table[1,2] + cm$table[2,1] + cm$table[2,2])
# Precision
precisao <- cm$table[1,1] / (cm$table[1,1] + cm$table[1,2])
sensibilidade <- cm$table[1,1] / (cm$table[1,1] + cm$table[2,1])
f1 <- (2 * sensibilidade * precisao) / (sensibilidade + precisao)
metricas <- data.frame(
"Acuracia"      = acuracia,
"Precisao"      = precisao,
"Sensibilidade" = sensibilidade,
"F1-Score"      = f1)
metricas
class1 <- predict(ajt.trn, newdata = mdl.vld, type = "response")
class2 <- mdl.vld[target_names]
pred <- prediction(class1, class2)
perf <- performance(pred, "tpr", "fpr")
# Gerando uma curva ROC em R
plot(perf, col = rainbow(10, alpha = NULL))
chisq.test(previsoes$observado, previsoes$previsto)
predict(ajt.trn,
newdata = mdl.tst,
type = "response") %>%
round() %>%
factor(labels = c("Negative", "Positive")) -> predicao
CrossTable(predicao, prop.t = T, digits = 2)
View(moda)
